<!DOCTYPE html>
<html>
<head>
    <title>Audio Transcription</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }
        .container {
            background-color: white;
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        #recordButton {
            background-color: #4CAF50;
            color: white;
            padding: 10px 20px;
            border: none;
            border-radius: 4px;
            cursor: pointer;
            font-size: 16px;
            margin: 10px 0;
            transition: background-color 0.3s;
        }
        #recordButton.recording {
            background-color: #f44336;
            animation: pulse 1.5s infinite;
        }
        @keyframes pulse {
            0% { transform: scale(1); }
            50% { transform: scale(1.05); }
            100% { transform: scale(1); }
        }
        #visualizer {
            width: 100%;
            height: 100px;
            background-color: #f0f0f0;
            margin: 20px 0;
            border-radius: 4px;
        }
        #status {
            margin: 10px 0;
            color: #666;
        }
        #transcription {
            margin-top: 20px;
            padding: 10px;
            background-color: #f9f9f9;
            border-radius: 4px;
            min-height: 50px;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Audio Transcription</h1>
        <button id="recordButton">Start Recording</button>
        <div id="status">Click 'Start Recording' to begin</div>
        <canvas id="visualizer"></canvas>
        <div id="transcription"></div>
    </div>

    <script>
        let mediaRecorder;
        let audioChunks = [];
        let isRecording = false;
        let audioContext;
        let analyser;
        let canvas = document.getElementById('visualizer');
        let canvasCtx = canvas.getContext('2d');
        let recordButton = document.getElementById('recordButton');
        let statusDiv = document.getElementById('status');
        let transcriptionDiv = document.getElementById('transcription');

        // Set up canvas size
        function setupCanvas() {
            canvas.width = canvas.offsetWidth;
            canvas.height = canvas.offsetHeight;
        }
        setupCanvas();
        window.addEventListener('resize', setupCanvas);

        async function startRecording() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                
                // Set up audio context and analyser
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                const source = audioContext.createMediaStreamSource(stream);
                analyser = audioContext.createAnalyser();
                analyser.fftSize = 2048;
                source.connect(analyser);
                
                mediaRecorder = new MediaRecorder(stream);
                audioChunks = [];

                mediaRecorder.ondataavailable = (event) => {
                    audioChunks.push(event.data);
                };

                mediaRecorder.onstop = async () => {
                    statusDiv.textContent = 'Processing audio...';
                    const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
                    
                    // Convert blob to base64
                    const reader = new FileReader();
                    reader.readAsDataURL(audioBlob);
                    reader.onloadend = async () => {
                        const base64Audio = reader.result;
                        
                        try {
                            const response = await fetch('/transcribe', {
                                method: 'POST',
                                headers: {
                                    'Content-Type': 'application/json',
                                },
                                body: JSON.stringify({ audio: base64Audio })
                            });
                            
                            const data = await response.json();
                            if (data.error) {
                                statusDiv.textContent = `Error: ${data.error}`;
                            } else {
                                statusDiv.textContent = 'Transcription complete!';
                                transcriptionDiv.textContent = data.transcription;
                            }
                        } catch (error) {
                            statusDiv.textContent = `Error: ${error.message}`;
                        }
                    };
                };

                mediaRecorder.start();
                isRecording = true;
                recordButton.textContent = 'Stop Recording';
                recordButton.classList.add('recording');
                statusDiv.textContent = 'Recording...';
                
                // Start visualization
                drawVisualizer();
            } catch (error) {
                statusDiv.textContent = `Error: ${error.message}`;
            }
        }

        function stopRecording() {
            if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                mediaRecorder.stop();
                mediaRecorder.stream.getTracks().forEach(track => track.stop());
                isRecording = false;
                recordButton.textContent = 'Start Recording';
                recordButton.classList.remove('recording');
                statusDiv.textContent = 'Processing...';
            }
        }

        function drawVisualizer() {
            if (!isRecording) return;

            requestAnimationFrame(drawVisualizer);
            
            const bufferLength = analyser.frequencyBinCount;
            const dataArray = new Uint8Array(bufferLength);
            analyser.getByteTimeDomainData(dataArray);
            
            canvasCtx.fillStyle = '#f0f0f0';
            canvasCtx.fillRect(0, 0, canvas.width, canvas.height);
            canvasCtx.lineWidth = 2;
            canvasCtx.strokeStyle = '#4CAF50';
            canvasCtx.beginPath();
            
            const sliceWidth = canvas.width * 1.0 / bufferLength;
            let x = 0;
            
            for (let i = 0; i < bufferLength; i++) {
                const v = dataArray[i] / 128.0;
                const y = v * canvas.height / 2;
                
                if (i === 0) {
                    canvasCtx.moveTo(x, y);
                } else {
                    canvasCtx.lineTo(x, y);
                }
                
                x += sliceWidth;
            }
            
            canvasCtx.lineTo(canvas.width, canvas.height / 2);
            canvasCtx.stroke();
        }

        recordButton.addEventListener('click', () => {
            if (!isRecording) {
                startRecording();
            } else {
                stopRecording();
            }
        });
    </script>
</body>
</html> 